{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir72syVHRY6d"
   },
   "source": [
    "# Pre-processing Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w7qcswO1KqC"
   },
   "source": [
    "## Introduction\n",
    "In this tutorial, you'll learn how to use Pandas to perform some basic pre-processing tasks that you may need to carry out to clean your data for the project before you can import it to your database. \n",
    "\n",
    "Specifically, the tutorial covers:\n",
    "\n",
    "\n",
    "*   Removal of rows with missing values\n",
    "*   Replacement of missing values with default values\n",
    "*   Dectection of entity resolution problems\n",
    "*   Simple entity resolution\n",
    "*   Removal of unpaired entities\n",
    "*   Replacement of categorical variables with indicators\n",
    "*   Identification of candidate indices\n",
    "*   Data exportation\n",
    "\n",
    "To edit and run the code throughout the tutorial, open the notebook in \"playground mode\" using the button in the upper right corner.\n",
    "\n",
    "After going through the tutorial, try the accompanying exercises to practice what you learned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a65RsmMHyqcB"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29vshYPDU7e8"
   },
   "source": [
    "Run the cell below to import necessary modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymfuSljIMWdO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqDcfFDuU-56"
   },
   "source": [
    "The tutorial uses two datasets:\n",
    "1. The [subset of U.S. census data](https://drive.google.com/open?id=1WB60Q6VJYyjbE8h8WED2mfi8Ae8LzoRU) maintained by the UCI Machine Learning Repository, which we used in the last tutorial.\n",
    "2. A [modified life expectancy dataset](https://drive.google.com/open?id=1DrjuDzQ_rcgULkm3zQqwLQQGIuDInoj5) compiled by the World Health Organization.\n",
    "\n",
    "For the purpose of the tutorial, imagine we're planning to build an application that will draw on both these datasets. It could, for example, help users learn about the relationship between how immigrants fair in the United States and health indicators in their native country. \n",
    "\n",
    "To prepare the datasets for ingestion into the database, we need to:\n",
    "1. Clean missing / misentered values\n",
    "2. Detect and solve entity resolution problems\n",
    "3. Replace categorical variables with numeric indicators for efficiency\n",
    "4. Export the data\n",
    "\n",
    "Before doing any of this, we need to import the datasets to _pandas_ `DataFrames`. We'll follow the data importation procedure outlined in the [EDA tutorial](https://drive.google.com/open?id=1Cy3izai9zLQYTCTQF9IwkcuLmNArcKZO). Add the datasets to your Google Drive using the links above, then mount your Drive to the notebook by running the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "bG0H3MGaNA8M",
    "outputId": "55a326d5-5424-4567-b98a-cff72709bc6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "prefix = '/content/drive'\n",
    "from google.colab import drive\n",
    "drive.mount(prefix, force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2fr3ngdPlJ_"
   },
   "source": [
    "Now, copy the paths to the life expectancy dataset and census dataset to the `le_path` and `census_path` variables respectively in the cell below. Then, run the cell to save your variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSpkgOZHPkuE"
   },
   "outputs": [],
   "source": [
    "le_path = '/content/drive/My Drive/CIS550/life_expectancy.csv' # Path to life expectancy dataset in your drive\n",
    "census_path = '/content/drive/My Drive/CIS550/adult.data' # Path to census subset in your drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqbLr8CSQBmP"
   },
   "source": [
    "Finally, run the cell below to load the census data into a `DataFrame` named `census` and the life expectancy data into a `DataFrame` named `le`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "vFyiS_Vocek_",
    "outputId": "dde2a8f0-db5f-41a7-a4d7-0f1f71bdbbc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>le_birth</th>\n",
       "      <th>le_birth_male</th>\n",
       "      <th>le_birth_female</th>\n",
       "      <th>le_60</th>\n",
       "      <th>le_60_male</th>\n",
       "      <th>le_60_female</th>\n",
       "      <th>hle_birth</th>\n",
       "      <th>hle_birth_male</th>\n",
       "      <th>hle_birth_female</th>\n",
       "      <th>hle_60</th>\n",
       "      <th>hle_60_male</th>\n",
       "      <th>hle_60_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2016</td>\n",
       "      <td>62.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>16.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>63.2</td>\n",
       "      <td>61.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>53.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>54.1</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>64.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>62.7</td>\n",
       "      <td>61.5</td>\n",
       "      <td>64.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>62.2</td>\n",
       "      <td>60.9</td>\n",
       "      <td>63.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  le_birth  ...  hle_60  hle_60_male  hle_60_female\n",
       "0  Afghanistan  2016      62.7  ...    11.3         10.9           11.7\n",
       "1  Afghanistan  2015      63.2  ...    11.2         10.8           11.6\n",
       "2  Afghanistan  2014      63.0  ...     NaN          NaN            NaN\n",
       "3  Afghanistan  2013      62.7  ...     NaN          NaN            NaN\n",
       "4  Afghanistan  2012      62.2  ...     NaN          NaN            NaN\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'maritial-status',\n",
    "             'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "             'hours-per-week', 'native-country', 'income']\n",
    "census = pd.read_csv(census_path, header=None, names=col_names)\n",
    "le = pd.read_csv(le_path)\n",
    "le.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P1kCEk63bqK"
   },
   "source": [
    "###  Life Expectancy Dataset Column Meanings\n",
    "In the life expectancy dataset above, `le` stands for \"life expectancy\", `hle` stands for \"healthy life expectancy\". Life expectancy means the number of years a person can expect to live, and healthy life expectancy means the number of years a person can be in good health. \n",
    "\n",
    "The columns with `60` in their names give life expectancy or healthy life expectancy for 60 year olds living in the given country at the given year. The columns with `birth` in their names give life expectancy or healthy life expectancy for individuals born in the given country in the given year. \n",
    "\n",
    "The columns with the `male` suffix give life expectancy statistics for men. The columns with `female` suffix give life expectancy statistics for women. And the column with no `male` or `female` suffix give statistics for an arbitrary person. \n",
    "\n",
    "Now, let's start our pre-processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3wKVKlWFRWo"
   },
   "source": [
    "## Clean Missing Values\n",
    "\n",
    "For application quality control, we would like to ensure our database doesn't contain any missing values. \n",
    "\n",
    "As we saw in the EDA tutorial, the census dataset has missing values in `workclass`, `occupation`, and `native-country`. Similar analysis of the life expectancy data indicates all the `hle` columns also have missing values (encoded as NaN's). \n",
    "\n",
    "To resolve these problems, we will: \n",
    "1. Remove all rows from the census dataset that have at least one missing value, and \n",
    "2. Replace the missing `hle` values with appropriate defaults.\n",
    "\n",
    "Let's see how. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "827kKMEqLUfr"
   },
   "source": [
    "### Remove Rows with Missing Values\n",
    "Let's remove all rows from the census dataset that contain at least one missing value. \n",
    "\n",
    "*Recall from the EDA tutorial that the census dataset denotes missing values with \" ?\".*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1PZkkAMNzjV"
   },
   "source": [
    "First, we generate a dataframe where each element indicates whether that element was missing in the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "lffPhXIBOL7U",
    "outputId": "87e50e38-e74f-49a9-ab16-1344b5769f50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>maritial-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  workclass  fnlwgt  ...  hours-per-week  native-country  income\n",
       "0  False      False   False  ...           False           False   False\n",
       "1  False      False   False  ...           False           False   False\n",
       "2  False      False   False  ...           False           False   False\n",
       "3  False      False   False  ...           False           False   False\n",
       "4  False      False   False  ...           False           False   False\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_census = census.isin([\" ?\"])\n",
    "missing_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gG4n2CrHOaYT"
   },
   "source": [
    "Next, we collapse the dataframe of missing indicators into a `Series` of indicators giving whether *any* of the values in each row are missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEBR1TmZPIGB"
   },
   "outputs": [],
   "source": [
    "missing_census = missing_census.any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzNqH_ytPJqL"
   },
   "source": [
    "Finally, we use this `Series` to subset the original census dataset to only contain those rows where there aren't any missing values. \n",
    "\n",
    "*Note: Applying `~` to a boolean `Series` negates the truth value of each element*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfBfl2oKPrzS"
   },
   "outputs": [],
   "source": [
    "census = census.loc[(~missing_census).values, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kf-xFqxdRu7v"
   },
   "source": [
    "As a sanity check, we ensure none of the elements in `census` equal \" ?\" now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "m3R-DzDXR8SV",
    "outputId": "2ea08992-89ea-4946-fe9e-ddd3d493f5bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.isin([\" ?\"]).any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_z-BnZySNqB"
   },
   "source": [
    "Great! It looks like we dropped all the rows with missing values from the census dataset. Now, let's turn our attention to the life expectancy data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkt2n1jKMx-0"
   },
   "source": [
    "### Replace Missing Values with Defaults\n",
    "For the life expectancy dataset, more than 70% of rows have at least 1 missing value. But only the healthy life expectancy values are missing. All of the vanilla life expectancy statistics are in tact. As a result, throwing out all of the rows with missing values would be very costly.\n",
    "\n",
    "Instead, we'll replace all missing values with reasonable defaults based on known values. Our replacement formula takes advantage of two facts:\n",
    "\n",
    "1. Every `hle` statistic has an `le` counterpart (e.g. `hle_60_male` and `le_60_male`). This allows us to express each `hle` value as $\\text{hle}=\\frac{\\text{hle}}{\\text{le}}\\cdot \\text{le}$. Let `hle_prop` denote $\\frac{\\text{hle}}{\\text{le}}$. This value represents the portion of their expected lifetime a person can expect to remain healthy for. \n",
    "\n",
    "  Let's make this concrete with an example. Consider life expectancy and healthy life expectancy for 60 year-old men in Afghanistan in 2016. `hle_60_male=10.9` and `le_male_60=15.5`, so `hle_prop` $=\\frac{\\text{hle}}{\\text{le}}=\\frac{10.9}{15.5}=0.70$. In words, a 60 year-old man in Afghanistan in 2016 can expect to spend about 70% of his remaining life healthy. \n",
    "\n",
    "2. In every case there's a missing `hle` statistic, the corresponding `le` statistic is known. \n",
    "\n",
    "\n",
    "Using these facts, we compute default value for a missing `hle` value as the product of the known `le` value for the focal row and the mean `hle_prop` value, computed using all rows where the relevant `le` and `hle` values are known. \n",
    "\n",
    "This formula is unbiased under the assumption that the relationship between life expectancy and healthy life expectancy is the same for country-year pairs where healthy life expectancy is known and pairs where it's unknown. \n",
    "\n",
    "\n",
    "Now, let's actually compute the formula. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ub8XnRxYdi-W"
   },
   "source": [
    "First, we make a map of `hle` statistics to corresponding `le` statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "sHzU4zbsdaA0",
    "outputId": "df41ae68-a167-413f-a280-18bfd73a35a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hle_60': 'le_60',\n",
       " 'hle_60_female': 'le_60_female',\n",
       " 'hle_60_male': 'le_60_male',\n",
       " 'hle_birth': 'le_birth',\n",
       " 'hle_birth_female': 'le_birth_female',\n",
       " 'hle_birth_male': 'le_birth_male'}"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_map = dict()\n",
    "for col in le.columns:\n",
    "  if \"hle\" in col:\n",
    "    col_map[col] = col[1:]  # removing the first letter\n",
    "col_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh1Zfcc_eF82"
   },
   "source": [
    "Now, we compute the mean `hle_prop` for each `hle` statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "RxPhaBIreMqA",
    "outputId": "bed0fff7-2ddb-4c4d-a68c-1f1c0c9aab08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hle_60': 0.7596736425993857,\n",
       " 'hle_60_female': 0.7565391913858537,\n",
       " 'hle_60_male': 0.7634433440990085,\n",
       " 'hle_birth': 0.8796379697074018,\n",
       " 'hle_birth_female': 0.8734263702625841,\n",
       " 'hle_birth_male': 0.8860401169946647}"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_map = dict()\n",
    "for hle_col, le_col in col_map.items():\n",
    "  prop_map[hle_col] = (le[hle_col] / le[le_col]).mean(skipna=True)\n",
    "prop_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DeEDBwJqWmu"
   },
   "source": [
    "Next, we extract the indices of the rows with missing values for each `hle` statistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHMqxi26et5p"
   },
   "outputs": [],
   "source": [
    "missing_map = dict()\n",
    "for hle_col in col_map.keys():\n",
    "  is_missing = le[hle_col].isna()\n",
    "  missing_map[hle_col] = le.index[is_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC3gq3NlrAyS"
   },
   "source": [
    "Finally, we iterate over the `hle` statistics and replace each missing value with the corresponding `le` statistic multiplied by the corresponding proportion. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "69VzkmpqrRB2",
    "outputId": "57d2e923-c0ec-4985-9d45-b9287451b245"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>le_birth</th>\n",
       "      <th>le_birth_male</th>\n",
       "      <th>le_birth_female</th>\n",
       "      <th>le_60</th>\n",
       "      <th>le_60_male</th>\n",
       "      <th>le_60_female</th>\n",
       "      <th>hle_birth</th>\n",
       "      <th>hle_birth_male</th>\n",
       "      <th>hle_birth_female</th>\n",
       "      <th>hle_60</th>\n",
       "      <th>hle_60_male</th>\n",
       "      <th>hle_60_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2016</td>\n",
       "      <td>62.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>16.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>52.100000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>11.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>63.2</td>\n",
       "      <td>61.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>52.600000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>11.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>64.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>55.417192</td>\n",
       "      <td>54.668675</td>\n",
       "      <td>56.248658</td>\n",
       "      <td>12.306713</td>\n",
       "      <td>11.757027</td>\n",
       "      <td>12.861166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>62.7</td>\n",
       "      <td>61.5</td>\n",
       "      <td>64.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>55.153301</td>\n",
       "      <td>54.491467</td>\n",
       "      <td>55.986630</td>\n",
       "      <td>12.306713</td>\n",
       "      <td>11.757027</td>\n",
       "      <td>12.785512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>62.2</td>\n",
       "      <td>60.9</td>\n",
       "      <td>63.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>54.713482</td>\n",
       "      <td>53.959843</td>\n",
       "      <td>55.549917</td>\n",
       "      <td>12.230746</td>\n",
       "      <td>11.680683</td>\n",
       "      <td>12.709858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  le_birth  ...     hle_60  hle_60_male  hle_60_female\n",
       "0  Afghanistan  2016      62.7  ...  11.300000    10.900000      11.700000\n",
       "1  Afghanistan  2015      63.2  ...  11.200000    10.800000      11.600000\n",
       "2  Afghanistan  2014      63.0  ...  12.306713    11.757027      12.861166\n",
       "3  Afghanistan  2013      62.7  ...  12.306713    11.757027      12.785512\n",
       "4  Afghanistan  2012      62.2  ...  12.230746    11.680683      12.709858\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for hle_col, le_col in col_map.items():\n",
    "  le.loc[missing_map[hle_col], hle_col] = le.loc[missing_map[hle_col], le_col] * prop_map[hle_col]\n",
    "le.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAUAoHqFrjI7"
   },
   "source": [
    "As a sanity check, let's make sure there are no `NaN`'s left in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1GCtPalSr0CQ",
    "outputId": "29f1f398-7a94-46b1-eaf1-bcae6d6c9b6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MstrO8P9LZrT"
   },
   "source": [
    "### Remove rows, replace with defaults, or ignore?\n",
    "None of these options is strictly better than the others. Depending on your application and what exactly is missing from the data, any choice could be acceptable.\n",
    "\n",
    "This doesn't mean you can make the decision thoughtlessly. In context, certain choices can be misguided. For example, you can't ignore missing values in a column you plan to use as a table index, and you can't throw out all rows with missing values if 95% of your rows are incomplete. \n",
    "\n",
    "So for the project, think carefully about which approach is appropriate for your application and data. Feel free to have a discussion with your project mentor. We expect you to justify whatever decision you make in your project report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98CCMF7osH_c"
   },
   "source": [
    "## Entity Resolution\n",
    "\n",
    "Now that we've handled missing values in both datasets, we turn our attention to performing entity resolution on the entities common to both. In this case, those common entities are countries.\n",
    "\n",
    "To perform entity resolution, we will:\n",
    "1. Determine whether both datasets use the same names to refer to all countries\n",
    "2. Edit the names in one dataset to match the other, if necessary\n",
    "\n",
    "In the general case, you may also need to detect when datasets refer to different entities using the same name/ID and disambiguate these references. This may happen when handling datasets that contain multiple people with the same name, for example. But we don't need to worry about it here because the names of countries are well-known and distict. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9hb43PAv2Xa"
   },
   "source": [
    "### Detect Inconsistent Names\n",
    "Let's compile a list of all country names in both datasets, then inspect it for repetitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qSUfNMexChR"
   },
   "source": [
    "First, we extract the unique names of countries from both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GttZPEV4xGEu"
   },
   "outputs": [],
   "source": [
    "census_countries = census[\"native-country\"].unique()\n",
    "le_countries = le[\"country\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60IeS3yJyJD_"
   },
   "source": [
    "Now, we combine these into one set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n416xpP1yO85"
   },
   "outputs": [],
   "source": [
    "countries = set(census_countries.tolist() + le_countries.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhg4MRXCyrsf"
   },
   "source": [
    "Let's inspect the contents of the set. The output is automatically sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ljqsQSoVy5PZ",
    "outputId": "d0db1451-a6b5-4117-db51-640f029de0e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Cambodia',\n",
       " ' Canada',\n",
       " ' China',\n",
       " ' Columbia',\n",
       " ' Cuba',\n",
       " ' Dominican-Republic',\n",
       " ' Ecuador',\n",
       " ' El-Salvador',\n",
       " ' England',\n",
       " ' France',\n",
       " ' Germany',\n",
       " ' Greece',\n",
       " ' Guatemala',\n",
       " ' Haiti',\n",
       " ' Holand-Netherlands',\n",
       " ' Honduras',\n",
       " ' Hong',\n",
       " ' Hungary',\n",
       " ' India',\n",
       " ' Iran',\n",
       " ' Ireland',\n",
       " ' Italy',\n",
       " ' Jamaica',\n",
       " ' Japan',\n",
       " ' Laos',\n",
       " ' Mexico',\n",
       " ' Nicaragua',\n",
       " ' Outlying-US(Guam-USVI-etc)',\n",
       " ' Peru',\n",
       " ' Philippines',\n",
       " ' Poland',\n",
       " ' Portugal',\n",
       " ' Puerto-Rico',\n",
       " ' Scotland',\n",
       " ' South',\n",
       " ' Taiwan',\n",
       " ' Thailand',\n",
       " ' Trinadad&Tobago',\n",
       " ' United-States',\n",
       " ' Vietnam',\n",
       " ' Yugoslavia',\n",
       " 'Afghanistan',\n",
       " 'Albania',\n",
       " 'Algeria',\n",
       " 'Angola',\n",
       " 'Antigua and Barbuda',\n",
       " 'Argentina',\n",
       " 'Armenia',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Azerbaijan',\n",
       " 'Bahamas',\n",
       " 'Bahrain',\n",
       " 'Bangladesh',\n",
       " 'Barbados',\n",
       " 'Belarus',\n",
       " 'Belgium',\n",
       " 'Belize',\n",
       " 'Benin',\n",
       " 'Bhutan',\n",
       " 'Bolivia (Plurinational State of)',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Botswana',\n",
       " 'Brazil',\n",
       " 'Brunei Darussalam',\n",
       " 'Bulgaria',\n",
       " 'Burkina Faso',\n",
       " 'Burundi',\n",
       " 'Cabo Verde',\n",
       " 'Cambodia',\n",
       " 'Cameroon',\n",
       " 'Canada',\n",
       " 'Central African Republic',\n",
       " 'Chad',\n",
       " 'Chile',\n",
       " 'China',\n",
       " 'Colombia',\n",
       " 'Comoros',\n",
       " 'Congo',\n",
       " 'Costa Rica',\n",
       " 'Croatia',\n",
       " 'Cuba',\n",
       " 'Cyprus',\n",
       " 'Czechia',\n",
       " \"Côte d'Ivoire\",\n",
       " \"Democratic People's Republic of Korea\",\n",
       " 'Democratic Republic of the Congo',\n",
       " 'Denmark',\n",
       " 'Djibouti',\n",
       " 'Dominican Republic',\n",
       " 'Ecuador',\n",
       " 'Egypt',\n",
       " 'El Salvador',\n",
       " 'Equatorial Guinea',\n",
       " 'Eritrea',\n",
       " 'Estonia',\n",
       " 'Eswatini',\n",
       " 'Ethiopia',\n",
       " 'Fiji',\n",
       " 'Finland',\n",
       " 'France',\n",
       " 'Gabon',\n",
       " 'Gambia',\n",
       " 'Georgia',\n",
       " 'Germany',\n",
       " 'Ghana',\n",
       " 'Greece',\n",
       " 'Grenada',\n",
       " 'Guatemala',\n",
       " 'Guinea',\n",
       " 'Guinea-Bissau',\n",
       " 'Guyana',\n",
       " 'Haiti',\n",
       " 'Honduras',\n",
       " 'Hungary',\n",
       " 'Iceland',\n",
       " 'India',\n",
       " 'Indonesia',\n",
       " 'Iran (Islamic Republic of)',\n",
       " 'Iraq',\n",
       " 'Ireland',\n",
       " 'Israel',\n",
       " 'Italy',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Jordan',\n",
       " 'Kazakhstan',\n",
       " 'Kenya',\n",
       " 'Kiribati',\n",
       " 'Kuwait',\n",
       " 'Kyrgyzstan',\n",
       " \"Lao People's Democratic Republic\",\n",
       " 'Latvia',\n",
       " 'Lebanon',\n",
       " 'Lesotho',\n",
       " 'Liberia',\n",
       " 'Libya',\n",
       " 'Lithuania',\n",
       " 'Luxembourg',\n",
       " 'Madagascar',\n",
       " 'Malawi',\n",
       " 'Malaysia',\n",
       " 'Maldives',\n",
       " 'Mali',\n",
       " 'Malta',\n",
       " 'Mauritania',\n",
       " 'Mauritius',\n",
       " 'Mexico',\n",
       " 'Micronesia (Federated States of)',\n",
       " 'Mongolia',\n",
       " 'Montenegro',\n",
       " 'Morocco',\n",
       " 'Mozambique',\n",
       " 'Myanmar',\n",
       " 'Namibia',\n",
       " 'Nepal',\n",
       " 'Netherlands',\n",
       " 'New Zealand',\n",
       " 'Nicaragua',\n",
       " 'Niger',\n",
       " 'Nigeria',\n",
       " 'Norway',\n",
       " 'Oman',\n",
       " 'Pakistan',\n",
       " 'Panama',\n",
       " 'Papua New Guinea',\n",
       " 'Paraguay',\n",
       " 'Peru',\n",
       " 'Philippines',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'Qatar',\n",
       " 'Republic of Korea',\n",
       " 'Republic of Moldova',\n",
       " 'Republic of North Macedonia',\n",
       " 'Romania',\n",
       " 'Russian Federation',\n",
       " 'Rwanda',\n",
       " 'Saint Lucia',\n",
       " 'Saint Vincent and the Grenadines',\n",
       " 'Samoa',\n",
       " 'Sao Tome and Principe',\n",
       " 'Saudi Arabia',\n",
       " 'Senegal',\n",
       " 'Serbia',\n",
       " 'Seychelles',\n",
       " 'Sierra Leone',\n",
       " 'Singapore',\n",
       " 'Slovakia',\n",
       " 'Slovenia',\n",
       " 'Solomon Islands',\n",
       " 'Somalia',\n",
       " 'South Africa',\n",
       " 'South Sudan',\n",
       " 'Spain',\n",
       " 'Sri Lanka',\n",
       " 'Sudan',\n",
       " 'Suriname',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'Syrian Arab Republic',\n",
       " 'Tajikistan',\n",
       " 'Thailand',\n",
       " 'Timor-Leste',\n",
       " 'Togo',\n",
       " 'Tonga',\n",
       " 'Trinidad and Tobago',\n",
       " 'Tunisia',\n",
       " 'Turkey',\n",
       " 'Turkmenistan',\n",
       " 'Uganda',\n",
       " 'Ukraine',\n",
       " 'United Arab Emirates',\n",
       " 'United Kingdom of Great Britain and Northern Ireland',\n",
       " 'United Republic of Tanzania',\n",
       " 'United States of America',\n",
       " 'Uruguay',\n",
       " 'Uzbekistan',\n",
       " 'Vanuatu',\n",
       " 'Venezuela (Bolivarian Republic of)',\n",
       " 'Viet Nam',\n",
       " 'Yemen',\n",
       " 'Zambia',\n",
       " 'Zimbabwe'}"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKmwYr4gzEmZ"
   },
   "source": [
    "Immediately, we see that many of the names have spaces prepended to them that appear to be preventing matches. Let's print the lists of names from each dataset separately to see where these are coming from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "id": "qEzkEXHuzOv5",
    "outputId": "b4272ea4-99fa-4453-8d73-babfbbba5c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census Countries\n",
      "[' United-States' ' Cuba' ' Jamaica' ' India' ' Mexico' ' Puerto-Rico'\n",
      " ' Honduras' ' England' ' Canada' ' Germany' ' Iran' ' Philippines'\n",
      " ' Poland' ' Columbia' ' Cambodia' ' Thailand' ' Ecuador' ' Laos'\n",
      " ' Taiwan' ' Haiti' ' Portugal' ' Dominican-Republic' ' El-Salvador'\n",
      " ' France' ' Guatemala' ' Italy' ' China' ' South' ' Japan' ' Yugoslavia'\n",
      " ' Peru' ' Outlying-US(Guam-USVI-etc)' ' Scotland' ' Trinadad&Tobago'\n",
      " ' Greece' ' Nicaragua' ' Vietnam' ' Hong' ' Ireland' ' Hungary'\n",
      " ' Holand-Netherlands']\n",
      "\n",
      "LE Countries\n",
      "['Afghanistan' 'Albania' 'Algeria' 'Angola' 'Antigua and Barbuda'\n",
      " 'Argentina' 'Armenia' 'Australia' 'Austria' 'Azerbaijan' 'Bahamas'\n",
      " 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus' 'Belgium' 'Belize' 'Benin'\n",
      " 'Bhutan' 'Bolivia (Plurinational State of)' 'Bosnia and Herzegovina'\n",
      " 'Botswana' 'Brazil' 'Brunei Darussalam' 'Bulgaria' 'Burkina Faso'\n",
      " 'Burundi' 'Cabo Verde' 'Cambodia' 'Cameroon' 'Canada'\n",
      " 'Central African Republic' 'Chad' 'Chile' 'China' 'Colombia' 'Comoros'\n",
      " 'Congo' 'Costa Rica' \"Côte d'Ivoire\" 'Croatia' 'Cuba' 'Cyprus' 'Czechia'\n",
      " \"Democratic People's Republic of Korea\"\n",
      " 'Democratic Republic of the Congo' 'Denmark' 'Djibouti'\n",
      " 'Dominican Republic' 'Ecuador' 'Egypt' 'El Salvador' 'Equatorial Guinea'\n",
      " 'Eritrea' 'Estonia' 'Eswatini' 'Ethiopia' 'Fiji' 'Finland' 'France'\n",
      " 'Gabon' 'Gambia' 'Georgia' 'Germany' 'Ghana' 'Greece' 'Grenada'\n",
      " 'Guatemala' 'Guinea' 'Guinea-Bissau' 'Guyana' 'Haiti' 'Honduras'\n",
      " 'Hungary' 'Iceland' 'India' 'Indonesia' 'Iran (Islamic Republic of)'\n",
      " 'Iraq' 'Ireland' 'Israel' 'Italy' 'Jamaica' 'Japan' 'Jordan' 'Kazakhstan'\n",
      " 'Kenya' 'Kiribati' 'Kuwait' 'Kyrgyzstan'\n",
      " \"Lao People's Democratic Republic\" 'Latvia' 'Lebanon' 'Lesotho' 'Liberia'\n",
      " 'Libya' 'Lithuania' 'Luxembourg' 'Madagascar' 'Malawi' 'Malaysia'\n",
      " 'Maldives' 'Mali' 'Malta' 'Mauritania' 'Mauritius' 'Mexico'\n",
      " 'Micronesia (Federated States of)' 'Mongolia' 'Montenegro' 'Morocco'\n",
      " 'Mozambique' 'Myanmar' 'Namibia' 'Nepal' 'Netherlands' 'New Zealand'\n",
      " 'Nicaragua' 'Niger' 'Nigeria' 'Norway' 'Oman' 'Pakistan' 'Panama'\n",
      " 'Papua New Guinea' 'Paraguay' 'Peru' 'Philippines' 'Poland' 'Portugal'\n",
      " 'Qatar' 'Republic of Korea' 'Republic of Moldova' 'Romania'\n",
      " 'Russian Federation' 'Rwanda' 'Saint Lucia'\n",
      " 'Saint Vincent and the Grenadines' 'Samoa' 'Sao Tome and Principe'\n",
      " 'Saudi Arabia' 'Senegal' 'Serbia' 'Seychelles' 'Sierra Leone' 'Singapore'\n",
      " 'Slovakia' 'Slovenia' 'Solomon Islands' 'Somalia' 'South Africa'\n",
      " 'South Sudan' 'Spain' 'Sri Lanka' 'Sudan' 'Suriname' 'Sweden'\n",
      " 'Switzerland' 'Syrian Arab Republic' 'Tajikistan' 'Thailand'\n",
      " 'Republic of North Macedonia' 'Timor-Leste' 'Togo' 'Tonga'\n",
      " 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'Turkmenistan' 'Uganda'\n",
      " 'Ukraine' 'United Arab Emirates'\n",
      " 'United Kingdom of Great Britain and Northern Ireland'\n",
      " 'United Republic of Tanzania' 'United States of America' 'Uruguay'\n",
      " 'Uzbekistan' 'Vanuatu' 'Venezuela (Bolivarian Republic of)' 'Viet Nam'\n",
      " 'Yemen' 'Zambia' 'Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "print(\"Census Countries\")\n",
    "print(census_countries)\n",
    "print(\"\")\n",
    "print(\"LE Countries\")\n",
    "print(le_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG_chEiw2-js"
   },
   "source": [
    "The output above indicates the names with spaces are coming from the census dataset. So let's remove those spaces, recompile the list, and take look for countries that appear twice in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MhC7d3s43wTg",
    "outputId": "c4d60a37-598c-4d60-ad16-903e577308bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Afghanistan',\n",
       " 'Albania',\n",
       " 'Algeria',\n",
       " 'Angola',\n",
       " 'Antigua and Barbuda',\n",
       " 'Argentina',\n",
       " 'Armenia',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Azerbaijan',\n",
       " 'Bahamas',\n",
       " 'Bahrain',\n",
       " 'Bangladesh',\n",
       " 'Barbados',\n",
       " 'Belarus',\n",
       " 'Belgium',\n",
       " 'Belize',\n",
       " 'Benin',\n",
       " 'Bhutan',\n",
       " 'Bolivia (Plurinational State of)',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Botswana',\n",
       " 'Brazil',\n",
       " 'Brunei Darussalam',\n",
       " 'Bulgaria',\n",
       " 'Burkina Faso',\n",
       " 'Burundi',\n",
       " 'Cabo Verde',\n",
       " 'Cambodia',\n",
       " 'Cameroon',\n",
       " 'Canada',\n",
       " 'Central African Republic',\n",
       " 'Chad',\n",
       " 'Chile',\n",
       " 'China',\n",
       " 'Colombia',\n",
       " 'Columbia',\n",
       " 'Comoros',\n",
       " 'Congo',\n",
       " 'Costa Rica',\n",
       " 'Croatia',\n",
       " 'Cuba',\n",
       " 'Cyprus',\n",
       " 'Czechia',\n",
       " \"Côte d'Ivoire\",\n",
       " \"Democratic People's Republic of Korea\",\n",
       " 'Democratic Republic of the Congo',\n",
       " 'Denmark',\n",
       " 'Djibouti',\n",
       " 'Dominican Republic',\n",
       " 'Dominican-Republic',\n",
       " 'Ecuador',\n",
       " 'Egypt',\n",
       " 'El Salvador',\n",
       " 'El-Salvador',\n",
       " 'England',\n",
       " 'Equatorial Guinea',\n",
       " 'Eritrea',\n",
       " 'Estonia',\n",
       " 'Eswatini',\n",
       " 'Ethiopia',\n",
       " 'Fiji',\n",
       " 'Finland',\n",
       " 'France',\n",
       " 'Gabon',\n",
       " 'Gambia',\n",
       " 'Georgia',\n",
       " 'Germany',\n",
       " 'Ghana',\n",
       " 'Greece',\n",
       " 'Grenada',\n",
       " 'Guatemala',\n",
       " 'Guinea',\n",
       " 'Guinea-Bissau',\n",
       " 'Guyana',\n",
       " 'Haiti',\n",
       " 'Holand-Netherlands',\n",
       " 'Honduras',\n",
       " 'Hong',\n",
       " 'Hungary',\n",
       " 'Iceland',\n",
       " 'India',\n",
       " 'Indonesia',\n",
       " 'Iran',\n",
       " 'Iran (Islamic Republic of)',\n",
       " 'Iraq',\n",
       " 'Ireland',\n",
       " 'Israel',\n",
       " 'Italy',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Jordan',\n",
       " 'Kazakhstan',\n",
       " 'Kenya',\n",
       " 'Kiribati',\n",
       " 'Kuwait',\n",
       " 'Kyrgyzstan',\n",
       " \"Lao People's Democratic Republic\",\n",
       " 'Laos',\n",
       " 'Latvia',\n",
       " 'Lebanon',\n",
       " 'Lesotho',\n",
       " 'Liberia',\n",
       " 'Libya',\n",
       " 'Lithuania',\n",
       " 'Luxembourg',\n",
       " 'Madagascar',\n",
       " 'Malawi',\n",
       " 'Malaysia',\n",
       " 'Maldives',\n",
       " 'Mali',\n",
       " 'Malta',\n",
       " 'Mauritania',\n",
       " 'Mauritius',\n",
       " 'Mexico',\n",
       " 'Micronesia (Federated States of)',\n",
       " 'Mongolia',\n",
       " 'Montenegro',\n",
       " 'Morocco',\n",
       " 'Mozambique',\n",
       " 'Myanmar',\n",
       " 'Namibia',\n",
       " 'Nepal',\n",
       " 'Netherlands',\n",
       " 'New Zealand',\n",
       " 'Nicaragua',\n",
       " 'Niger',\n",
       " 'Nigeria',\n",
       " 'Norway',\n",
       " 'Oman',\n",
       " 'Outlying-US(Guam-USVI-etc)',\n",
       " 'Pakistan',\n",
       " 'Panama',\n",
       " 'Papua New Guinea',\n",
       " 'Paraguay',\n",
       " 'Peru',\n",
       " 'Philippines',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'Puerto-Rico',\n",
       " 'Qatar',\n",
       " 'Republic of Korea',\n",
       " 'Republic of Moldova',\n",
       " 'Republic of North Macedonia',\n",
       " 'Romania',\n",
       " 'Russian Federation',\n",
       " 'Rwanda',\n",
       " 'Saint Lucia',\n",
       " 'Saint Vincent and the Grenadines',\n",
       " 'Samoa',\n",
       " 'Sao Tome and Principe',\n",
       " 'Saudi Arabia',\n",
       " 'Scotland',\n",
       " 'Senegal',\n",
       " 'Serbia',\n",
       " 'Seychelles',\n",
       " 'Sierra Leone',\n",
       " 'Singapore',\n",
       " 'Slovakia',\n",
       " 'Slovenia',\n",
       " 'Solomon Islands',\n",
       " 'Somalia',\n",
       " 'South',\n",
       " 'South Africa',\n",
       " 'South Sudan',\n",
       " 'Spain',\n",
       " 'Sri Lanka',\n",
       " 'Sudan',\n",
       " 'Suriname',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'Syrian Arab Republic',\n",
       " 'Taiwan',\n",
       " 'Tajikistan',\n",
       " 'Thailand',\n",
       " 'Timor-Leste',\n",
       " 'Togo',\n",
       " 'Tonga',\n",
       " 'Trinadad&Tobago',\n",
       " 'Trinidad and Tobago',\n",
       " 'Tunisia',\n",
       " 'Turkey',\n",
       " 'Turkmenistan',\n",
       " 'Uganda',\n",
       " 'Ukraine',\n",
       " 'United Arab Emirates',\n",
       " 'United Kingdom of Great Britain and Northern Ireland',\n",
       " 'United Republic of Tanzania',\n",
       " 'United States of America',\n",
       " 'United-States',\n",
       " 'Uruguay',\n",
       " 'Uzbekistan',\n",
       " 'Vanuatu',\n",
       " 'Venezuela (Bolivarian Republic of)',\n",
       " 'Viet Nam',\n",
       " 'Vietnam',\n",
       " 'Yemen',\n",
       " 'Yugoslavia',\n",
       " 'Zambia',\n",
       " 'Zimbabwe'}"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_census_countries = list()\n",
    "for country in census_countries.tolist():\n",
    "  if country[0] == \" \":\n",
    "    fixed_census_countries.append(country[1:])\n",
    "countries = set(fixed_census_countries + le_countries.tolist())\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyw0H0PN7QCg"
   },
   "source": [
    "The output contains 9 countries with multiple names:\n",
    "\n",
    "*   \"United States of America\" and \"United-States\"\n",
    "*   \"Trinidad and Tobago\" and \"Trinidad&Tobago\"\n",
    "*   \"Dominican Republic\" and \"Dominican-Republic\"\n",
    "*   \"El-Salvador\" and \"El Salvador\"\n",
    "*   \"Columbia\" and \"Colombia\"\n",
    "*   \"Netherlands\" and \"Holand-Netherlands\"\n",
    "*   \"Laos\" and \"Lao People's Democratic Republic\"\n",
    "*   \"Iran\" and \"Iran (Islamic Republic of)\"\n",
    "*   \"Viet Nam\" and \"Vietnam\"\n",
    "\n",
    "Relatedly, the output contains an entry for the United Kingdom, as well as entries for Scotland and England, which are part of the UK. \n",
    "\n",
    "*Republic of Korea and the Democratic People's Republic of Korea are different countries. Congo and Democratic Republic of the Congo are also different.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBPPffqk-IkX"
   },
   "source": [
    "### Resolve Inconsistent Names\n",
    "Now, let's fix the problems the we uncovered in the previous step.\n",
    "\n",
    "First, we trim the whitespace off the start and end of the country names in both datasets to handle that space issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Q1oX0BKAArE"
   },
   "outputs": [],
   "source": [
    "census[\"native-country\"] = census[\"native-country\"].str.strip()\n",
    "le[\"country\"] = le[\"country\"].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19nOkPXuA2xC"
   },
   "source": [
    "For each country with multiple names, we need to purge one of the names from the dataset. We'll do this by replacing all usages of one name with the other. \n",
    "\n",
    "We'll also replace all substitute all usages Scotland and England for the U.K. This solution sacrifices some precision, but at least we avoid the incorrect conclusion that there's no valid counterpart for rows containing Scotland and England.  \n",
    "\n",
    "To accomplish this, we first create a `Series` of the countries with multiple names, where of each element is the name we'll purge, and the value is name we'll keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "5ff8F_8zDL_A",
    "outputId": "cb5025ad-02a6-489b-eea0-a0dfed1ad8d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United-States                                                United States of America\n",
       "Trinadad&Tobago                                                   Trinidad and Tobago\n",
       "Dominican-Republic                                                 Dominican Republic\n",
       "Columbia                                                                     Colombia\n",
       "Lao People's Democratic Republic                                                 Laos\n",
       "Scotland                            United Kingdom of Great Britain and Northern I...\n",
       "England                             United Kingdom of Great Britain and Northern I...\n",
       "Iran (Islamic Republic of)                                                       Iran\n",
       "Holand-Netherlands                                                        Netherlands\n",
       "Viet Nam                                                                      Vietnam\n",
       "El-Salvador                                                               El Salvador\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_map = {\n",
    "     \"United-States\": \"United States of America\",\n",
    "     \"Trinadad&Tobago\": \"Trinidad and Tobago\",\n",
    "     \"Dominican-Republic\": \"Dominican Republic\",\n",
    "     \"Columbia\" : \"Colombia\",\n",
    "     \"Lao People's Democratic Republic\": \"Laos\",\n",
    "     \"Scotland\": \"United Kingdom of Great Britain and Northern Ireland\",\n",
    "     \"England\": \"United Kingdom of Great Britain and Northern Ireland\",\n",
    "     \"Iran (Islamic Republic of)\": \"Iran\",\n",
    "     \"Holand-Netherlands\": \"Netherlands\",\n",
    "     \"Viet Nam\" : \"Vietnam\",\n",
    "     \"El-Salvador\": \"El Salvador\"\n",
    "}\n",
    "name_series = pd.Series(data=list(name_map.values()), index=list(name_map.keys()))\n",
    "name_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptKLCctdD3JQ"
   },
   "source": [
    "Next, we find the indices of all usages of the names we're purging in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HyFc3AgD2U_"
   },
   "outputs": [],
   "source": [
    "purge_list = list(name_map.keys())\n",
    "census_idx = census.index[census[\"native-country\"].isin(purge_list)]\n",
    "le_idx = le.index[le[\"country\"].isin(purge_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DpY9tzWEQTk"
   },
   "source": [
    "Using these indices, we extract the names that we need to update as `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3RXvDbBEfnh"
   },
   "outputs": [],
   "source": [
    "census_problems = census.loc[census_idx, \"native-country\"]\n",
    "le_problems = le.loc[le_idx, \"country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1PlMNNhF6Il"
   },
   "source": [
    "Next, we replace the problematic names in these `Series` with the appropriate counterparts by indexing `name_series` with them. \n",
    "\n",
    "*The operations in the cell below replace the names correctly because `name_series` maps each name we wanted to purge to the we wanted to replace it with.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJw-v1HrE14w"
   },
   "outputs": [],
   "source": [
    "census_fixed = name_series.loc[census_problems.values].values\n",
    "le_fixed = name_series.loc[le_problems.values].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u8jJZzjH9MM"
   },
   "source": [
    "Finally, we update the dataframes with the fixed names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkQKesqmICgE"
   },
   "outputs": [],
   "source": [
    "census.loc[census_idx, \"native-country\"] = census_fixed\n",
    "le.loc[le_idx, \"country\"] = le_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QL3WaoCICHp"
   },
   "source": [
    "### Remove Unpaired Entities\n",
    "In some cases, you may want to exclude entities that only appear in one dataset or the other from your database. Let's suppose that's the case here and remove all countries that only appear in one dataset or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqNfzN7tJL7U"
   },
   "source": [
    "As before, we first extract the full list of countries found in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dr0C2XkcJcAW"
   },
   "outputs": [],
   "source": [
    "census_countries = census[\"native-country\"].unique().tolist()\n",
    "le_countries = le[\"country\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auiotb7RJhQc"
   },
   "source": [
    "Then, we convert these lists to sets and use set-difference operations to find the countries that only appear in one set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ec2dYksZJsQa"
   },
   "outputs": [],
   "source": [
    "census_countries = set(census_countries)\n",
    "le_countries = set(le_countries)\n",
    "cen_diff = census_countries.difference(le_countries)\n",
    "le_diff = le_countries.difference(census_countries)\n",
    "total_diff = list(cen_diff) + list(le_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X1tJo6LPBIY"
   },
   "source": [
    "Finally, we drop all rows from both datasets that contain countries that match any of the countries in this list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0Bx25wbPLQg"
   },
   "outputs": [],
   "source": [
    "le = le.loc[~le[\"country\"].isin(total_diff), :]\n",
    "census = census.loc[~census[\"native-country\"].isin(total_diff), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MZVmgiXRqv5"
   },
   "source": [
    "## Replace Categorical Variables with Indicators\n",
    "\n",
    "Depending on your application, you may want to replace some of your text-based categorical variables with numeric equivalents. This substitution can reduce the runtime of some queries and decrease the your tables require. It can be especially fruitful for columns you plan to use as indices.  \n",
    "\n",
    "Let's see an example. Below, we'll convert the columns containing countries in our datasets to numeric equivalents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8NVf1uoTxSz"
   },
   "source": [
    "First, we create a `Series` that maps each country name to an integer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "pkg6Kst9T4Hd",
    "outputId": "5b3d1e89-e31c-48eb-8a9f-12af37b2bf7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cambodia                                                 0\n",
       "Canada                                                   1\n",
       "China                                                    2\n",
       "Colombia                                                 3\n",
       "Cuba                                                     4\n",
       "Dominican Republic                                       5\n",
       "Ecuador                                                  6\n",
       "El Salvador                                              7\n",
       "France                                                   8\n",
       "Germany                                                  9\n",
       "Greece                                                  10\n",
       "Guatemala                                               11\n",
       "Haiti                                                   12\n",
       "Honduras                                                13\n",
       "Hungary                                                 14\n",
       "India                                                   15\n",
       "Iran                                                    16\n",
       "Ireland                                                 17\n",
       "Italy                                                   18\n",
       "Jamaica                                                 19\n",
       "Japan                                                   20\n",
       "Laos                                                    21\n",
       "Mexico                                                  22\n",
       "Netherlands                                             23\n",
       "Nicaragua                                               24\n",
       "Peru                                                    25\n",
       "Philippines                                             26\n",
       "Poland                                                  27\n",
       "Portugal                                                28\n",
       "Thailand                                                29\n",
       "Trinidad and Tobago                                     30\n",
       "United Kingdom of Great Britain and Northern Ireland    31\n",
       "United States of America                                32\n",
       "Vietnam                                                 33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries = le[\"country\"].unique()\n",
    "country_codes = pd.Series(index=all_countries, data=np.arange(len(all_countries)))\n",
    "country_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhH-RBVjUI7c"
   },
   "source": [
    "Next, we use this `Series` to map all countries in both datasets to the corresponding integers by indexing the `Series` with the names of the countries in the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "mi5HamRVUo3f",
    "outputId": "0032634e-d219-4597-9832-aaf5dbbccc48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>maritial-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt  ... hours-per-week  native-country  income\n",
       "0   39          State-gov   77516  ...             40              32   <=50K\n",
       "1   50   Self-emp-not-inc   83311  ...             13              32   <=50K\n",
       "2   38            Private  215646  ...             40              32   <=50K\n",
       "3   53            Private  234721  ...             40              32   <=50K\n",
       "4   28            Private  338409  ...             40               4   <=50K\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le[\"country\"] = country_codes.loc[le[\"country\"]].values\n",
    "census[\"native-country\"] = country_codes.loc[census[\"native-country\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kB_y0zbWVET5"
   },
   "source": [
    "Finally, we convert the columns to integer types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNgBAFypVZn3"
   },
   "outputs": [],
   "source": [
    "le[\"country\"] = le[\"country\"].astype(np.int64)\n",
    "census[\"native-country\"] = census[\"native-country\"].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIKECQ-8a2y4"
   },
   "source": [
    "## Find an Index\n",
    "\n",
    "Before ingesting our data into the database, we need to find a unique index for each table. Let's do this for the life expectancy dataset. \n",
    "\n",
    "### Single Column Index\n",
    "The fastest way to determine whether any single column is unique is to check whether the number of unique values in the candidate column equals the number of elements. For example, let's find out whether `country` could be the index.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dpZM9Jr5b7rb",
    "outputId": "0ae57e2f-c89e-4bfd-dc13-2e0e2909a76c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(le[\"country\"].unique()) == len(le[\"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBjWVulycIi2"
   },
   "source": [
    "### Multi-Column Index\n",
    "\n",
    "When there's not an individual column that can act as an index, we search for combinations of columns that can make a unique index when combined. \n",
    "\n",
    "To check a candidate set of columns:\n",
    "1. Call `DataFrame.groupby()` on the list of candidate columns. *This creates a group of rows for each unique combination of candidate olumn values that appears in the Dataframe*\n",
    "2. Call `GroupBy.size()` on the resulting grouped dataframe. *This counts the number of rows in each group*\n",
    "3. Check whether every group has exactly 1 row. \n",
    "\n",
    "We use this procedure below to check whether `country` and `year` can function as a joint index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "hHUnR5_1ee9D",
    "outputId": "cea79831-dcd4-4a21-d5ce-6b724829495d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country  year\n",
      "0        2000    1\n",
      "         2001    1\n",
      "         2002    1\n",
      "         2003    1\n",
      "         2004    1\n",
      "                ..\n",
      "33       2012    1\n",
      "         2013    1\n",
      "         2014    1\n",
      "         2015    1\n",
      "         2016    1\n",
      "Length: 578, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Group dataframe by candidate columns \n",
    "grouped_le = le.groupby([\"country\", \"year\"]) \n",
    "# Step 2: Count rows in each group\n",
    "counts = grouped_le.size()\n",
    "print(counts)\n",
    "# Step 3: Check whether every value equals 1\n",
    "(counts == 1).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zObIej43fEXV"
   },
   "source": [
    "Great! This means no country-year pair appears more than once in the life expectancy table, so we can use `country` and `year` in combination as the index. \n",
    "\n",
    "For the census dataset, you'd need every column to create a unique index (Check this for yourself). So we'll just plan to use the arbitrary, unique integers `census.index` as our table index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpNzpcioVZVW"
   },
   "source": [
    "## Export Data\n",
    "After cleaning our datasets, resolving entity resolution problems, and choosing indices, we're ready to ingest our the data into our database.\n",
    "\n",
    "In the past, students have found using Python for data ingestion slow and frustrating, so we won't populate the database here. Instead, we'll export both datasets and the country codes to CSVs. Then, we'll show you how to ingest these CSVs into your database using MySQL Workbench in the tutorial on data ingestion. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p0w9RrcXhWw"
   },
   "source": [
    "First, convert the `Series` of country codes to an equivalent `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyBLaDbPYron"
   },
   "outputs": [],
   "source": [
    "country_codes = pd.DataFrame(data={'country': country_codes.index, 'code': country_codes.values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzRipkHDY25m"
   },
   "source": [
    "Next, we use `DataFrame.to_csv` to write each dataset to a CSV file with a descriptive name. \n",
    "\n",
    "*For `le` and `country_codes`, we set `index` to `False` because the indices of the `DataFrames` are meaningless integers that we don't need in our tables. For `census`, we rename the index and include it in the output because we decided  to use it as our table index, even though it's arbitrary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "-IxY6b2bgNU9",
    "outputId": "ff6883a1-169d-40d7-e8ec-9f88f052b651"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-01c8688baf0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"le.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcountry_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"country_codes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcensus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcensus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"census.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'country_codes' is not defined"
     ]
    }
   ],
   "source": [
    "le.to_csv(\"le.csv\", index=False)\n",
    "country_codes.to_csv(\"country_codes.csv\", index=False)\n",
    "census.index.name = \"id\"\n",
    "census.to_csv(\"census.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze_Ryi19ga7m"
   },
   "source": [
    "Finally, we download these files to our local machine, so we can put them into MySQL Workbench later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyC1g_Xsgfmm"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('census.csv') \n",
    "files.download(\"country_codes.csv\")\n",
    "files.download(\"le.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FavIv7NIC2_I"
   },
   "source": [
    "## Exercises\n",
    "Check out [these exercises](https://drive.google.com/open?id=1kjLaYC_KJUlltm-iAzgF5VmHgb7Uer0z) to practice the processing techniques you learned above!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9 - Processing Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
